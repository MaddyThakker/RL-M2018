{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example - 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = np.array(['^', '<', 'd', '>'])\n",
    "\n",
    "def get_next_state(state, action):\n",
    "    reward = -1\n",
    "    if(state[0] == 0 and state[1] == 0):\n",
    "        return 0, state\n",
    "    if(state[0] == 3 and state[1] == 3):\n",
    "        return 0, state\n",
    "    if(action == 0):\n",
    "        next_state = [state[0] - 1, state[1]]\n",
    "    if(action == 1):\n",
    "        next_state = [state[0], state[1]-1]\n",
    "    if(action == 2):\n",
    "        next_state = [state[0] + 1, state[1]]\n",
    "    if(action == 3):\n",
    "        next_state = [state[0], state[1]+1]\n",
    "    if(next_state[0] < 0 or next_state[0] >= 4 or next_state[1] < 0 or next_state[1] >= 4):\n",
    "        next_state = state\n",
    "    return reward, next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stuff():\n",
    "    iter_print-=1\n",
    "    print(value)\n",
    "    for s in state:\n",
    "        old_action = policies[s[0]][s[1]]\n",
    "        v_iter = []\n",
    "        for action in [0, 1, 2, 3]:\n",
    "            reward, next_state = get_next_state(s, action)\n",
    "            v_iter.append((reward + gamma*value[next_state[0]][next_state[1]]))\n",
    "        v = max(v_iter)\n",
    "        v_iter = np.array(v_iter)\n",
    "        best_action = np.argmax(v_iter)\n",
    "#         print(best_action, old_action, v_iter)\n",
    "        policies[s[0]][s[1]]  = best_action\n",
    "        all_actions[s[0]][s[1]] = [best_action]\n",
    "        if policy_stable and best_action != old_action:\n",
    "            policy_stable = False\n",
    "    if(policy_stable):\n",
    "        print(\"policy stable, breaking\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breaking 9.643180353791081e-06 1e-05\n",
      "breaking 0.0 1e-05\n",
      "breaking 0.0 1e-05\n",
      "policy stable, breaking\n"
     ]
    }
   ],
   "source": [
    "theta = 1e-5\n",
    "gamma = 1 # undiscounted task\n",
    "value = np.zeros([4, 4])\n",
    "state = [[i, j] for i in range(4) for j in range(4)]\n",
    "all_actions = [ [ [0, 1, 2, 3] for i in range(4) ] for j in range(4) ]\n",
    "policies = np.zeros(value.shape)\n",
    "\n",
    "iter_print = 3\n",
    "\n",
    "while True:\n",
    "    while True:\n",
    "        delta = 0\n",
    "        new_value = np.zeros([4, 4])\n",
    "        for s in state:            \n",
    "            v_iter = []\n",
    "            for action in all_actions[s[0]][s[1]]:\n",
    "                reward, next_state = get_next_state(s, action)\n",
    "    #             v_iter.append((reward + gamma*value_star[next_state[0]][next_state[1]]))\n",
    "                new_value[s[0]][s[1]] += (1/len(all_actions[s[0]][s[1]]))*(reward + gamma*value[next_state[0]][next_state[1]])\n",
    "    #     new_value[s[0]][s[1]] = max(v_iter)\n",
    "        delta = np.sum(abs(value - new_value))\n",
    "        value = new_value\n",
    "        if(iter_print > 0):\n",
    "            print_stuff()\n",
    "        if(delta < theta):\n",
    "            print(\"breaking\", delta, theta)\n",
    "            break\n",
    "    \n",
    "    policy_stable = True\n",
    "    for s in state:\n",
    "        old_action = policies[s[0]][s[1]]\n",
    "        v_iter = []\n",
    "        for action in [0, 1, 2, 3]:\n",
    "            reward, next_state = get_next_state(s, action)\n",
    "            v_iter.append((reward + gamma*value[next_state[0]][next_state[1]]))\n",
    "        v = max(v_iter)\n",
    "        v_iter = np.array(v_iter)\n",
    "        best_action = np.argmax(v_iter)\n",
    "#         print(best_action, old_action, v_iter)\n",
    "        policies[s[0]][s[1]]  = best_action\n",
    "        all_actions[s[0]][s[1]] = [best_action]\n",
    "        if policy_stable and best_action != old_action:\n",
    "            policy_stable = False\n",
    "    if(policy_stable):\n",
    "        print(\"policy stable, breaking\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^  <  <  <  \n",
      "^  ^  ^  d  \n",
      "^  ^  d  d  \n",
      "^  >  >  ^  \n"
     ]
    }
   ],
   "source": [
    "for x in policies:\n",
    "    for y in x:\n",
    "        print(chars[int(y)], end = '  ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
